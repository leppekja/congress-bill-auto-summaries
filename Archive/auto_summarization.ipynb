{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "auto-summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWCpqDuvzwKa"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchtext.vocab import GloVe\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import pandas as pd\n",
        "from numpy import floor\n",
        "from numpy.random import shuffle\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchtext.vocab import Vocab\n",
        "import torch.nn.functional as F\n",
        "from collections import Counter\n",
        "from functools import partial\n",
        "from ast import literal_eval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0757CIPQ1OPu"
      },
      "source": [
        "SEED = 1\n",
        "\n",
        "random.seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "torch.backends.cudnn.deterministic = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnZd3cxp3366"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6JUiJYoz6Dd"
      },
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvTZE3aiz-7m"
      },
      "source": [
        "df = pd.read_csv('Sample.csv', converters={'summary_clean': literal_eval, 'bill_clean': literal_eval})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es8qWJHW4vkm"
      },
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/Cleaned_Summaries_And_Bills.csv', converters={'summary_clean': literal_eval, 'bill_clean': literal_eval})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "2qHls_vmiO2c",
        "outputId": "9b8e4dcf-723f-466b-a70c-dedfc6527df3"
      },
      "source": [
        "fake_data = pd.DataFrame({'bill_clean':[['<sos>', 'make', 'all', 'drugs', 'legal', '<eos>']], 'summary_clean':[['<sos>', 'make', 'drugs', 'legal', '<eos>']]})\n",
        "fake_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>bill_clean</th>\n",
              "      <th>summary_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[&lt;sos&gt;, make, all, drugs, legal, &lt;eos&gt;]</td>\n",
              "      <td>[&lt;sos&gt;, make, drugs, legal, &lt;eos&gt;]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                bill_clean                       summary_clean\n",
              "0  [<sos>, make, all, drugs, legal, <eos>]  [<sos>, make, drugs, legal, <eos>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkgvU-vQ0RFZ"
      },
      "source": [
        "def compression(df):\n",
        "    return np.mean(df.summary_clean.apply(len) / df.bill_clean.apply(len))\n",
        "\n",
        "def trim_dataset(df, bottom_k_pct, top_k_pct):\n",
        "    '''\n",
        "    Remove the top and bottom n% records from the bills and summaries.\n",
        "    Expects tokenized and cleaned dataset.\n",
        "    Pass in pct as decimals.\n",
        "    '''\n",
        "    df['summary_length'] = df.summary_clean.apply(lambda x: len(x))\n",
        "    df['bill_length'] = df.bill_clean.apply(lambda x: len(x))\n",
        "    df['summary_rank'] = df.summary_length.rank(pct=True)\n",
        "    df['bill_rank'] = df.bill_length.rank(pct=True)\n",
        "    cut_df = df[(df.summary_rank >= bottom_k_pct) & (df.summary_rank <= top_k_pct) & (\n",
        "        df.bill_rank >= bottom_k_pct) & (df.bill_rank <= top_k_pct) & (df.summary_length <= df.bill_length)]\n",
        "\n",
        "    print('Cut ' + str(df.shape[0] - cut_df.shape[0]) + ' records.')\n",
        "    print('Count of records remaining: ', cut_df.shape[0])\n",
        "    print(f'New min summary length is {cut_df.summary_length.min()}')\n",
        "    print(f'New max summary length is {cut_df.summary_length.max()}')\n",
        "    print(f'New min bill length is {cut_df.bill_length.min()}')\n",
        "    print(f'New max bill length is {cut_df.bill_length.max()}')\n",
        "    print(f'Compression of summaries to bills is {compression(cut_df)}')\n",
        "    del cut_df['bill_length']\n",
        "    del cut_df['summary_length']\n",
        "    del cut_df['summary_rank']\n",
        "    del cut_df['bill_rank']\n",
        "    return cut_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs26fQTb1BMy",
        "outputId": "4a0a1f59-fa99-412e-ec7e-9d5ef4d6fd02"
      },
      "source": [
        "sample = trim_dataset(df, 0, .03)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cut 499 records.\n",
            "Count of records remaining:  1\n",
            "New min summary length is 17\n",
            "New max summary length is 17\n",
            "New min bill length is 160\n",
            "New max bill length is 160\n",
            "Compression of summaries to bills is 0.10625\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U3F60j_0mPN"
      },
      "source": [
        "def split(data, training_size, testing_size, valid_size, shuffle_data=True):\n",
        "    ''' Takes in a pandas dataframe as data. Returns three BillsDataset objects'''\n",
        "    assert training_size + testing_size + \\\n",
        "        valid_size == 1, 'Split sizes should sum to 1'\n",
        "\n",
        "    def split_index(size, index_length):\n",
        "        '''Converts decimal to # of samples to take'''\n",
        "        return int(floor(size * index_length))\n",
        "    # Split into training / testing / validation sets, assign as attributes.\n",
        "    indices = list(range(len(data)))\n",
        "\n",
        "    train_split = split_index(training_size, len(indices))\n",
        "    test_split = split_index(testing_size, len(indices))\n",
        "\n",
        "    if shuffle_data:\n",
        "        shuffle(indices)\n",
        "\n",
        "    training_data = data.iloc[indices[0:train_split]]\n",
        "    test_data = data.iloc[indices[train_split:train_split + test_split]]\n",
        "    validate_data = data.iloc[indices[train_split + test_split:]]\n",
        "\n",
        "    return (BillsDataset(training_data, 'summary_clean', 'bill_clean'),\n",
        "            BillsDataset(test_data, 'summary_clean', 'bill_clean'),\n",
        "            BillsDataset(validate_data, 'summary_clean', 'bill_clean'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWNLjeOV0qxD"
      },
      "source": [
        "class BillsDataset(Dataset):\n",
        "    \"\"\"\n",
        "    Dataset for Congressional Bills\n",
        "    Adapted from https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
        "    and from https://gist.github.com/kevinzakka/d33bf8d6c7f06a9d8c76d97a7879f5cb.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, df, summaries_col, bills_col, transform=None):\n",
        "        self.data = df.reset_index(drop=True)\n",
        "        self.labels = summaries_col\n",
        "        self.texts = bills_col\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        summary = self.data.loc[idx, self.labels]\n",
        "        bill = self.data.loc[idx, self.texts]\n",
        "\n",
        "        sample = {'summary': summary, 'bill': bill}\n",
        "\n",
        "        if self.transform:\n",
        "            sample = self.transform(sample)\n",
        "\n",
        "        return sample\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSzLni9G0a8O"
      },
      "source": [
        "# train, test, valid sizes, respectively\n",
        "train, test, validate = split(fake_data, 1, 0, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ud3Ax7_j1efO"
      },
      "source": [
        "def build_vocab(training_data, summary_col='summary', bill_col='bill', summaries=True, bills=True):\n",
        "    '''\n",
        "    Builds a Vocab object for a Dataset object.\n",
        "    If default BillsDataset object, summary and bill are dict keys.\n",
        "    '''\n",
        "    # Here I used a single counter for both bills and summaries\n",
        "    # Since we don't want to limit the vocab\n",
        "    # Which seems right but I have no idea\n",
        "    counter_words = Counter()\n",
        "\n",
        "    for index in range(len(training_data)):\n",
        "        example = training_data[index]\n",
        "        if summaries:\n",
        "          counter_words.update(example[summary_col])\n",
        "        if bills:\n",
        "          counter_words.update(example[bill_col])\n",
        "\n",
        "    return Vocab(counter_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUB7X4Ma07yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fc1d497-d3eb-43bb-aa0a-b8b130d0aa3f"
      },
      "source": [
        "vocab = build_vocab(train, 'summary','bill')\n",
        "print(f'Vocab size is {len(vocab)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocab size is 8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5K-hi8G0uNM"
      },
      "source": [
        "def get_dataloaders(batch_size, vocab, max_summary_length, max_bill_length, **kwargs):\n",
        "    '''\n",
        "    kwargs for training_data:, test_data:, and validation_data:.\n",
        "    Returns dict of dataloaders based on arg name input\n",
        "    '''\n",
        "    dataloaders = {}\n",
        "    # Set params for the collate function\n",
        "    # uses the max length of any bill and summary across the entire data set\n",
        "    collate_fn = partial(\n",
        "        collate_bills_fn, vocab=vocab, max_summary_length=max_summary_length, max_bill_length=max_bill_length)\n",
        "\n",
        "    for dataset_name, data in kwargs.items():\n",
        "        dataloaders[dataset_name] = DataLoader(\n",
        "            data, batch_size=batch_size,\n",
        "            shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    return dataloaders\n",
        "\n",
        "\n",
        "def collate_bills_fn(batch, vocab, max_summary_length=512, max_bill_length=2048):\n",
        "    '''\n",
        "    Collates the batches into the dataloader. Pads unequal lengths with zeros\n",
        "    based on the max lengths given.\n",
        "    '''\n",
        "    labels = []\n",
        "    texts = []\n",
        "    for idx, text_dict in enumerate(batch):\n",
        "        # Get the label and the text\n",
        "        label = text_dict['summary']\n",
        "        text = text_dict['bill'][::-1]\n",
        "        # Output for the sample\n",
        "        label_vectors = []\n",
        "        text_vectors = []\n",
        "        # Check lengths; see how much to pad\n",
        "        label_length = len(label)\n",
        "        text_length = len(text)\n",
        "        labels_to_pad = max_summary_length - label_length\n",
        "        text_to_pad = max_bill_length - text_length\n",
        "\n",
        "        if label_length < max_summary_length:\n",
        "            label.extend(['<pad>'] * labels_to_pad)\n",
        "            # label_vectors = F.pad(label_vectors, (0, 0, 0, labels_to_pad))\n",
        "        if text_length < max_bill_length:\n",
        "            text.extend(['<pad>'] * text_to_pad)\n",
        "            # text_vectors = F.pad(text_vectors, (0, 0, 0, text_to_pad))label_vectors = []\n",
        "\n",
        "        for word in label:\n",
        "            label_vectors.append(vocab.stoi[word])\n",
        "        for word in text:\n",
        "            text_vectors.append(vocab.stoi[word])\n",
        "\n",
        "\n",
        "        labels.append(torch.LongTensor(label_vectors))\n",
        "        texts.append(torch.LongTensor(text_vectors))\n",
        "    # Returns shape of (batch size, max_summary (or bill)_length) for each\n",
        "    return (torch.stack(labels), torch.stack(texts))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vd1Wx2a1f5I"
      },
      "source": [
        "# This results in (number of samples in each set / batch size) tuples (or iteration steps) of size (batch size, max length)\n",
        "# So if size of training is 15, and batch size is 5, enumerating through dataloader will have 3 steps of inputting label (batch size, summary_length) and text (batch size, bill length)\n",
        "dataloaders_dict = get_dataloaders(1, vocab, 5, 6, train_data=train,)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0nlEEiaLRlW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d9d12fa-1571-4a34-83ff-df61a902327c"
      },
      "source": [
        "l, f = next(iter(dataloaders_dict['train_data']))\n",
        "# print(l, [vocab.itos[x] for x in l.squeeze(0)])\n",
        "# print(f, [vocab.itos[x] for x in f.squeeze(0)])\n",
        "print(l)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[3, 6, 4, 5, 2]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47IKUh6O104N"
      },
      "source": [
        "def build_glove(vocab):\n",
        "  '''\n",
        "  Return the pretrained embeddings for the vocab words.\n",
        "  '''\n",
        "  # https://nlp.stanford.edu/projects/glove/\n",
        "  VECTORS_CACHE_DIR = './.vector_cache'\n",
        "  glove = GloVe(name='6B', cache=VECTORS_CACHE_DIR)\n",
        "  glove_vectors = glove.get_vecs_by_tokens(vocab.itos)\n",
        "  return glove_vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzwN2Z2-1utE"
      },
      "source": [
        "glove_vecs = build_glove(vocab)\n",
        "# glove_vecs will be size (vocab_size, 300)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MGYSLRF16h3"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_size,\n",
        "                 hidden_size,\n",
        "                 pretrained_embeddings,\n",
        "                 device,\n",
        "                 freeze_glove=False,\n",
        "                 ):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        # may have to adjust the padding_idx?\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            pretrained_embeddings, padding_idx=1, freeze=freeze_glove)\n",
        "\n",
        "        self.rnn = nn.LSTM(self.input_size, self.hidden_size, num_layers=4)\n",
        "\n",
        "    def forward(self, text):\n",
        "      '''\n",
        "      Text size is batch size, bill length\n",
        "      '''\n",
        "      # Embedded size is sequence length, batch size, glove vecs size\n",
        "      embedded = self.embedding(text).view(-1, len(text), 300)\n",
        "      # outputs is size (sequence length, batch_size, hidden_size)\n",
        "      outputs, (hidden, cell) = self.rnn(embedded)\n",
        "      # each of these are size (1, batch_size, hidden_size)\n",
        "      return hidden, cell"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXsKciUp2y_j"
      },
      "source": [
        "encoder = Encoder(300, 512, glove_vecs, DEVICE).to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i-tqTyGk2a6V"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, output_dim, hidden_dim, pretrained_embeddings, device, freeze_glove=False):\n",
        "        super().__init__()\n",
        "\n",
        "        # output dim should equal vocab size\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.rnn = nn.LSTM(300, hidden_dim, num_layers=4)\n",
        "        self.fc_out = nn.Linear(hidden_dim, output_dim).to(device)\n",
        "        # dim=1 applies LogSoftmax across rows\n",
        "        # Example:\n",
        "        # a = torch.Tensor([[1, 1, 1, 1], [5,60,5,25]])\n",
        "        # b = nn.LogSoftmax(dim=1)\n",
        "        # b(a)\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "        self.embedding = nn.Embedding.from_pretrained(\n",
        "            pretrained_embeddings, freeze=freeze_glove)\n",
        "\n",
        "    def forward(self, input_word, hidden, cell):\n",
        "        # print('ANSWER',input_word.size())\n",
        "        # Input word is initially\n",
        "        input_word = input_word.unsqueeze(0)\n",
        "        # print('input: ', input_word.size())\n",
        "        # print(vocab.itos[input_word])\n",
        "        # print('hidden: ', hidden.size())\n",
        "        # print('cell: ', cell.size())\n",
        "        embedded = self.embedding(input_word)  # .view(len(input), 300, -1)\n",
        "        # print('embedded_decode: ', embedded.size())\n",
        "        output, (hidden_new, cell_new) = self.rnn(embedded, (hidden, cell))\n",
        "        # print('new output: ',output.size())\n",
        "        # print('new hidden: ', hidden.size())\n",
        "        # print('new cell: ', cell.size())\n",
        "        prediction = self.softmax(self.fc_out(output.squeeze(0)))\n",
        "        # print('new prediction', prediction.size())\n",
        "        return prediction, hidden_new, cell_new"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-0YecV124iN"
      },
      "source": [
        "decoder = Decoder(len(vocab), 512, glove_vecs, DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y185AuTq2fAl"
      },
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, label, text):\n",
        "        batch_size = label.shape[0]\n",
        "        # print('batch size: ', batch_size)\n",
        "\n",
        "        label_length = label.shape[1]\n",
        "        # print('label_length: ', label_length)\n",
        "\n",
        "        vocab_size = self.decoder.output_dim\n",
        "\n",
        "        decode_outputs = torch.zeros(label_length, batch_size, vocab_size).to(self.device)\n",
        "        # print('outputs size: ', outputs.size())\n",
        "\n",
        "        hidden_enc, cell_enc = self.encoder(text)\n",
        "        input_word = label[:, 0]\n",
        "        # print(label.size())\n",
        "\n",
        "        for t in range(1, label_length):\n",
        "            # print('input word: ', vocab.itos[input_word[0]])\n",
        "\n",
        "            output, hidden, cell = self.decoder(input_word, hidden_enc, cell_enc)\n",
        "            # print('output size: ', output.size())\n",
        "            # print('outputs: ', outputs.size())\n",
        "            decode_outputs[t] = output\n",
        "            # pick next word\n",
        "            # top_choice = output.argmax(1)\n",
        "            top_choice = torch.max(output, dim=1)[1]\n",
        "            # print('predicted word:', ', '.join([vocab.itos[x] for x in top_choice]))\n",
        "            # Check loss here\n",
        "            # print('top choice', top_choice)\n",
        "            # somehow?\n",
        "            #input_word = top_choice\n",
        "            input_word = label[:, t]\n",
        "            hidden_enc = hidden\n",
        "            cell_enc =  cell\n",
        "        # print('outputs', outputs.size)\n",
        "        # print(outputs)\n",
        "        return decode_outputs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jRPx8aS28cP"
      },
      "source": [
        "seq = Seq2Seq(encoder, decoder, DEVICE).to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLvAmWLX2iSt"
      },
      "source": [
        "adams = optim.Adam(encoder.parameters(), lr=.1)\n",
        "PAD_TOKEN = vocab.stoi['<pad>']\n",
        "loss = nn.CrossEntropyLoss(ignore_index=PAD_TOKEN).to(DEVICE)  #ignore_index=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekmk8Pzp2hfq"
      },
      "source": [
        "def train_an_epoch(model, dataloader, optimizer, loss_function):\n",
        "    # loss_function = nn.CrossEntropyLoss().to(device)\n",
        "    model.train()\n",
        "    log_interval = 50\n",
        "    \n",
        "    for idx, (label, text) in enumerate(dataloader):\n",
        "        model.zero_grad()\n",
        "        label = label.to(DEVICE)\n",
        "        text = text.to(DEVICE)\n",
        "        output = model(label, text)\n",
        "        output_dim = output.shape[-1]\n",
        "        # print('initial', output.size())\n",
        "        # print(label.size())\n",
        "        output = output.view(-1, output_dim)\n",
        "        target = label.view(-1)\n",
        "        # print('output', output.size())\n",
        "        # print('target', target.size())\n",
        "        # print('TARGET: ', ' '.join([vocab.itos[x] for x in target]))\n",
        "        # print('PREDICTED: ', ' '.join([vocab.itos[x] for x in torch.max(output, dim=1)[1]]))\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "        # print('step', idx)\n",
        "      \n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            print(f'Iteration: {idx}; Loss: {loss:.3f}.')\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9rRUd19nBUlG"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDg2DK3lCb4n"
      },
      "source": [
        "def get_score(model, dataloader, loss_function):\n",
        "  model.eval()\n",
        "  total_loss = 0\n",
        "  with torch.no_grad():\n",
        "    for i, (label, text) in enumerate(dataloader):\n",
        "      label = label.to(DEVICE)\n",
        "      text = text.to(DEVICE)\n",
        "      output = model(label, text)\n",
        "      output_dim = output.shape[-1]\n",
        "      output = output.view(-1, output_dim)\n",
        "      target = label.view(-1)\n",
        "\n",
        "      loss = loss_function(output, target)\n",
        "      total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXhmCqJjcriH"
      },
      "source": [
        "# import gc\n",
        "# gc.collect()\n",
        "# torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mOMMpL94c2U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cd9af947-11cf-4229-d072-d6df2920fe59"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "EPOCHS = 30\n",
        "scores = []\n",
        "best_lost = float('inf')\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "  train_an_epoch(seq, dataloaders_dict['train_data'], adams, loss)\n",
        "  score = get_score(seq, dataloaders_dict['train_data'], loss)\n",
        "  # if score < best_lost:\n",
        "  #   best_lost = score\n",
        "  #   torch.save(seq.state_dict(), 's2s-model.pt')\n",
        "  scores.append(score)\n",
        "  if epoch % 100 == 0:\n",
        "    print(f'epoch {epoch}, score: {score:.3f}')\n",
        "\n",
        "plt.plot(range(1, EPOCHS+1), scores)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f2ad431d2d0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 464
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdKElwAJJqdW"
      },
      "source": [
        "def get_output(model, label, text):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    output = model(label, text)\n",
        "    output_dim = output.shape[-1]\n",
        "    output = output.view(-1, output_dim)\n",
        "    target = label.view(-1)\n",
        "\n",
        "    return target, output\n",
        "\n",
        "def make_prediction(model, vocab, label, text):\n",
        "  \"\"\"\n",
        "  label and text need to be submitted as dims [1, length]\n",
        "  May need to use unsqueeze. EX:\n",
        "  check = get_dataloaders(20, vocab, 63, 387,  check = test)\n",
        "  label, text = next(iter(check['check']))\n",
        "  l, p = make_prediction(seq, label[0].unsqueeze(0), text[0].unsqueeze(0))\n",
        "  \"\"\"\n",
        "  l, p = get_output(model, label, text)\n",
        "  p = p.argmax(1)\n",
        "  ls = ''\n",
        "  for idx, w in enumerate(l):\n",
        "    ls = ls + ' ' + str(vocab.itos[w])\n",
        "    if (str(vocab.itos[w]) == '<eos>') & (idx != 0):\n",
        "      break\n",
        "  ps = ''\n",
        "  for w in p:\n",
        "    word = str(vocab.itos[w])\n",
        "    # if (word != '<unk>') and (word != '<pad>'):\n",
        "    ps = ps + ' ' + word\n",
        "    if len(ps.split(' ')) == len(ls.split(' ')):\n",
        "      break\n",
        "  return ls, ps"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnILA8dIOs1Y"
      },
      "source": [
        "label, text = next(iter(dataloaders_dict['train_data']))\n",
        "label = label.to(DEVICE)\n",
        "text = text.to(DEVICE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BalnDn8EMGKK",
        "outputId": "2aeafb5c-61c9-4c19-a3ed-4914bcf8ae22"
      },
      "source": [
        "l, p = make_prediction(seq, vocab, label[0].unsqueeze(0), text[0].unsqueeze(0))\n",
        "print('TARGET: ', l)\n",
        "print('----')\n",
        "print('PREDICTION: ', p)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "something changed\n",
            "TARGET:   <sos> make drugs legal <eos>\n",
            "----\n",
            "PREDICTION:   <unk> make drugs drugs drugs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xwiq2-7u31il"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}